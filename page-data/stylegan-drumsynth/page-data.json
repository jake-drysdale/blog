{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/stylegan-drumsynth/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Jake Drysdale"}},"markdownRemark":{"id":"6dc590e6-3f01-54cc-98a2-a068398fc6bf","excerpt":"Drysdale, J. and Tomczak, M. and J. Hockman. 2021. Style-based Drum Synthesis with GAN Inversion. In Extended Abstracts for the Late-Breaking Demo Sessions of…","html":"<p>Drysdale, J. and Tomczak, M. and J. Hockman. 2021. Style-based Drum Synthesis with GAN Inversion. In <em>Extended Abstracts for the Late-Breaking Demo Sessions of the 22nd International Society for Music Information Retrieval Conference</em>, Online.\n[<a href=\"https://archives.ismir.net/ismir2021/latebreaking/000041.pdf\">paper</a>,\n<a href=\"/blog/190d8b84b7daadb18d800922bfe5b7b6/lbd_posterv2.pdf\">poster</a>]</p>\n<p>This blog post contains the supplementary material accompanying the late-breaking demo:  “Style-based Drum Synthesis with GAN Inversion” for the International Society for Music Information Retrieval (ISMIR).</p>\n<center><h3>Abstract</h3></center>\n<p>Neural audio synthesizers exploit deep learning as an alternative to traditional synthesizers that generate audio from hand-designed components such as oscillators and wavetables. For a neural audio synthesizer to be applicable to music creation, meaningful control over the output is essential. This paper provides an overview of an unsupervised approach to deriving useful feature controls learned by a generative model. A system for generation and transformation of drum samples using a style-based generative adversarial network (GAN) is proposed. The system provides functional control of style features of drum sounds based on principal component analysis (PCA) applied to the latent space. Additionally, we propose the use of an encoder trained to invert input drum sounds back to the latent space of the pre-trained GAN. We experiment with three modes of control and provide audio results on a supporting website. </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/blog/static/abf3683db81c45dafcbf0b363d7453ba/87670/training_fig.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAB7CAAAewgFu0HU+AAABsklEQVQoz1VSbW6cMBDlZrlKf/QQOUKk3iD92fQAlSKt0v7baD+iqI2ybJeksDbLgvjGYIwNBkMHqKJmkEYz4zfPnnlo/WRDr+AbJoOUc16WpRBiPPrPVKvAu56n67plWRokenHYZpuxbVBgSZIQQrIsgwC84ziQwmmRkfBJLyzE4/SIELBrzKcfLq8vPl6ZjwgQUso4jn3fPx6Pc2Ca5twcef5ps/35YxE+PcdhBNdooZPcfVnfXN16KBgfphRjjFJaVVVJaSslFGGKileB6zmrDV6t0hez6zqoa1NDVzd8eG+ybblqm34EAVcjm7aRhet3vO47NWPGZlpQeAb2/YfD4Te2hahZLZ5psEzwjkVpGEVxPN5fcdvEZ+ykYVzX9b9mmLOi9HZ5/+n689fF4mSfLPf07c+v749rg0ar5f1utwOYd3Zf98Z2vTX3LxhhEEKbtQEfELLHth0EDdDKxhTZhpxfBalZRfIcAK1sPeREbsDyErYwLuxtyDdJq8kG1XPZFIyBYGmawubzPK8F0DaAgxh29q55+lt6qIKGJYPBBUhlGAZCCGMM4s28cDiyD8NfbEcsLICSkd0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"training_procedure\"\n        title=\"training_procedure\"\n        src=\"/blog/static/abf3683db81c45dafcbf0b363d7453ba/fcda8/training_fig.png\"\n        srcset=\"/blog/static/abf3683db81c45dafcbf0b363d7453ba/12f09/training_fig.png 148w,\n/blog/static/abf3683db81c45dafcbf0b363d7453ba/e4a3f/training_fig.png 295w,\n/blog/static/abf3683db81c45dafcbf0b363d7453ba/fcda8/training_fig.png 590w,\n/blog/static/abf3683db81c45dafcbf0b363d7453ba/efc66/training_fig.png 885w,\n/blog/static/abf3683db81c45dafcbf0b363d7453ba/c83ae/training_fig.png 1180w,\n/blog/static/abf3683db81c45dafcbf0b363d7453ba/87670/training_fig.png 4552w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<center><h3>Code</h3></center>\n<p>The GitHub repository for this project is available <strong><a href=\"https://github.com/SoMA-group/stylegan-drumsynth\">here</a></strong>. The repo contains instructions for installation and usage for a TensorFlow implementation of the style-based drum synthesiser and audio inversion network. </p>\n<center><h3>Audio Examples</h3></center>\n<h1><center></h1>\n<h4>Training Data Vs Generations</h4>\n<p>An comparison between: (left) a random selection of some examples from the dataset used in training and, (right) a random selection of drum sound generations.</p>\n<figure>\n    <figcaption>Kick drums</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/fada2b5eafe741e2e39a8f5420e89f9c/kicks_real.wav\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"/blog/134744d9bbd155c716d2c7d4b1aa3b44/kick_generations_demo.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Snare drums</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/0b096000a710b035bc647ed618715b3d/snares_real.wav\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"/blog/62349e55fe1324949eddbe22481dace2/snare_generations_demo.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Cymbals</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/4d9e5fb1fe120be9880d72bbcf354e17/hats_real.wav\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"/blog/6d1efdde12e893371901ae12cbfe8094/hat_generations_demo.wav\">\n\t</audio>\n</figure>\n<h4>Audio Inversion Network</h4>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/blog/static/1318d804d685bf064e8dd7267168d884/73caa/inversion_network.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 22.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA6klEQVQI1yWN3U6DMACFeQrexr0X4do9hddeTCWYmCXcLBIIQevM3DqxBZpS3A9sOnEkS5fSrtnOxbn6zncMIYSUUil1aTJPsymqy/VmWR35cQxeD1JM2gocKneL42ahGSE7dY4Rx7FlWYwxPW7bFs++siQNRj5N8gzhz/cAVPRhCd1xCH7Kl933rt5c9/tRFHVdZ3ieZ5qm4zjaRCkFQTx9m9wP7mq28kf+k/s4hGDI4M3g9rlE/jpPZvCq17Ntm3Nu6E9CiF5qk+4CkTIvCkxyiP+bZv4RLvje3aLwl4V/JdivlFQ4TS/wCd2ayrX+Ej/XAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"inversion_network\"\n        title=\"inversion_network\"\n        src=\"/blog/static/1318d804d685bf064e8dd7267168d884/fcda8/inversion_network.png\"\n        srcset=\"/blog/static/1318d804d685bf064e8dd7267168d884/12f09/inversion_network.png 148w,\n/blog/static/1318d804d685bf064e8dd7267168d884/e4a3f/inversion_network.png 295w,\n/blog/static/1318d804d685bf064e8dd7267168d884/fcda8/inversion_network.png 590w,\n/blog/static/1318d804d685bf064e8dd7267168d884/efc66/inversion_network.png 885w,\n/blog/static/1318d804d685bf064e8dd7267168d884/73caa/inversion_network.png 1110w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>An A-B comparsion of encoding audio input (A) with the audio inversion network and drum sound generations (B) with the inverted latent code. (Left) the audio input and, (right) the corresponding generation.</p>\n<figure>\n    <figcaption>Kick drums</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/1f584bca2789efb16d4b6069f86a638a/kick_encoder_A.wav\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"/blog/e16830fdfb409d71271fd0e742e0cf09/kick_encoder_B.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Snare drums</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/095fa01b404ad8fcbe1d13dc7afd954b/snare_encoder_A.wav\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"/blog/240421640c1e8218318d5d678ed88513/snare_encoder_B.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Cymbals</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/e3061cd9f51427b56d0152a4dbbe8e69/hat_encoder_A.wav\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"/blog/6b8a4d076148e202c732310df559109a/hat_encoder_B.wav\">\n\t</audio>\n</figure>\n<p>Additionally, the examples below demonstrate the systems capacity to generate drum sounds from alternative audio inputs such as beatboxing and sliced breakbeats. </p>\n<figure>\n    <figcaption>Beatbox to drum sound</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/1298da851692ede95864b6ff5567b04e/beatbox_to_gan.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Hip-hop breakbeat to drum sound</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/91a36207532e028d16a3cb72d4cb758e/hiphop_to_gan.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Amen break to drum sound</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/61f1aebafa04046939568da50511386b/amen_to_gan.wav\">\n\t</audio>\n</figure>\n<h4>Usage demonstration</h4>\n<p>Example usage within loop-based electronic music compositions.\nThe percussive elements of the following tracks were created using a selection\nof samples from the generated data. A light amount of post-processing (equalisation and volume envelope shaping)\nwas applied to mix the sounds.</p>\n<figure>\n    <figcaption>Track 1: Hip hop demo</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/7da59eabcb45b5231b0d5426173c21fa/hiphopdemo.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Track 2: Drum and bass demo</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/94ea879a4cd8db0512786e42af715ab8/drumandbassdemo.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Track 3: Breakbeat interpolation demo</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/e82a80f63dd47c169072c508e4d03e0b/break-morphing.wav\">\n\t</audio>\n</figure>\n<!---\n##### Interpolating between two arbitrary drum sounds\n\nBelow are some examples of the systems capacity reconstruct two arbitrary and performing interpolation between them. (Left) source A, (right) source 2, and (below) interpolation between A and B. (under construction)\n\n\n<figure>\n    <figcaption>Kick-to-kick interpolation</figcaption>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n</figure>\n\n<figure>\n    <figcaption>Snare-to-snare interpolation</figcaption>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n</figure>\n\n<figure>\n    <figcaption>hat-to-hat interpolation</figcaption>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n    <audio controls\n\t\tsrc=\"\">\n\t</audio>\n</figure>\n--->\n<p>Some more examples can be found here: <a href=\"https://soundcloud.com/beatsbygan\">https://soundcloud.com/beatsbygan</a></p>\n<h4>Interpolation demonstration</h4>\n<p>The proposed system learns to map points in the latent space to the generated waveforms. The structure of the latent space can be explored by interpolating between points in the space.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/blog/static/3c383a54fa5d20894d2085706ef0173e/0f903/z_spacev2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.4054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAB7CAAAewgFu0HU+AAAB4UlEQVQoz21SaY+bMBDl//+Yfq/SSjnYCFRyAOE2YHMYc4czBwnb2Y26/dCO7JH97Dd6fh5unuf3z2i7rqyq6X6fn/P7H/DfeN1/ZQ7mNE1FniuGIciy7pNj6AaMlnnR9T0cjeOoaRoOgrdfUlUUHqWHk/Z8TJhSrm3bJElCQpI4JhiQxIyJ43nIcBxxV2RZ13WLxcK0rCXPm4ZR970oSeMwlOczF4ZhlqbffvyUDPOEEKFRnqYsZVlVBj6u6xrIq9VKVtSNIDJK47xUDfMyjnGWcyxJYOxV9WjZvKZ+j3RZkpGi+/KJMlaWJZD5zUazTF7eZTRJh8bC7nS7s6bmIkoN2w4ICT3PMU0HIdf17KOCBClJWVVVwzAAeScflzuxYGnY16qPnvcJNwVHouhtfxBldalBPpgn3bQtG0pgDC8siqLv+/V6jRy0FyWa0Irljm4N41jQ9EM2mOl7noIscMU46cqS92wQYWKMwe2+6wRBsE1L2R+iOO6bFmReb9cGDMuyLAhBsufaDvaxgxzs+chxAL/dbvCRoHy73Q5Nu1/xLsFnEktrvum7wgs+/vn5fF4uFzCGMdCR+L4PagF8dQXguq5fr1cSBFEUAQ5bqAgIN3/GVwM9Hg9Av5j/a7G/y98LhFNGHB53gwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"z_space_fig\"\n        title=\"z_space_fig\"\n        src=\"/blog/static/3c383a54fa5d20894d2085706ef0173e/fcda8/z_spacev2.png\"\n        srcset=\"/blog/static/3c383a54fa5d20894d2085706ef0173e/12f09/z_spacev2.png 148w,\n/blog/static/3c383a54fa5d20894d2085706ef0173e/e4a3f/z_spacev2.png 295w,\n/blog/static/3c383a54fa5d20894d2085706ef0173e/fcda8/z_spacev2.png 590w,\n/blog/static/3c383a54fa5d20894d2085706ef0173e/efc66/z_spacev2.png 885w,\n/blog/static/3c383a54fa5d20894d2085706ef0173e/c83ae/z_spacev2.png 1180w,\n/blog/static/3c383a54fa5d20894d2085706ef0173e/0f903/z_spacev2.png 1719w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Figure 2: Interpolation in the latent space for kick drum generation. Kick drums are generated for each point along linear\npathsthrough the latent space (left). Paths are colour coded and subsequent generated audio appears across rows (right).</p>\n<h5>A to B interpolation</h5>\n<p>In the following examples, two generated drum samples are selected and their latent vectors are noted. A linear path of 30 steps between each latent vector is created and a waveform is generated for each of those 30 steps.</p>\n<p>Interpolating between Snare A and Snare B.</p>\n<figure>\n    <figcaption>Snare A</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/a530c5adc630412cbafb582a4cc37a56/snare_a.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Snare B</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/436abd619027e297afffb21117d89034/snare_b.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Linear interpolation</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/faf86ce4aa364ad5424af46d953ca334/demo1_interpolate.wav\">\n\t</audio>\n</figure>\n<p>Interpolating between Kick A and Kick B.</p>\n<figure>\n    <figcaption>Kick A</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/dfe0b4a25ea3859eddc8f668916957e3/kick_a.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Kick B</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/742442e55da50c7beabcd1fdfc0c7734/kick_b.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Linear interpolation</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/a84f8ea9acfa079a2770691a2c29f4d2/demo2_interpolate.wav\">\n\t</audio>\n</figure>\n<p>Interpolating between Cymbal A and Cymbal B.</p>\n<figure>\n    <figcaption>Cymbal A</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/09841e4a0aec0a946f1486c0360ab0f0/cymbal_a.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Cymbal B</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/1fbc99f06215f2f1496022fd8a81cdc5/cymbal_b.wav\">\n\t</audio>\n</figure>\n<figure>\n    <figcaption>Linear interpolation</figcaption>\n    <audio controls\n\t\tsrc=\"/blog/6ab3a48087e0a5f184d4acbb2cd752c0/demo3_interpolate.wav\">\n\t</audio>\n</figure>\n<h2>References</h2>\n<table>\n<thead>\n<tr>\n<th align=\"left\"><strong>[1]</strong></th>\n<th align=\"left\"><strong><a href=\"https://archives.ismir.net/ismir2021/latebreaking/000041.pdf\">Drysdale, J. and Tomczak, M. and J. Hockman. 2021. Style-based Drum Synthesis with GAN Inversion. In <em>Extended Abstracts for the Late-Breaking Demo Sessions of the 22nd International Society for Music Information Retrieval Conference</em>, Online.</a></strong></th>\n</tr>\n</thead>\n<tbody>\n</tbody>\n</table>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">@inproceedings{drysdale2021sds,\n  title={Style-based Drum Synthesis with GAN Inversion},\n  author={Drysdale, Jake and Tomczak, Maciej and Hockman, Jason},\n  booktitle = {Extended Abstracts for the Late-Breaking Demo Sessions of the 22nd\n  International Society for Music Information Retrieval (ISMIR) Conference.},\n  year={2021}\n}</code></pre></div>","frontmatter":{"title":"Style-based Drum Synthesis with GAN Inversion","date":"October 10, 2021","tags":["gans","drumsynth","ismir"],"description":"Style-based Adversarial Drum Synthesis and GAN Inversion","thumbnail":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+klEQVQY0w1P6Y6DIBj0/Z9ss81mt7GtKB4ooh8gh2DFao8lmR+TmWSOZNs2N88oywghx7F/Pp/H45EjRLvu/X5HLqepwDhiUlN0n89nhhAXIvLEOT9pUxNCGfPL8nq93BIa2oNUblnX+12NQPKiumWK8+M4DIgWl7yj3tjEed8DT2+oaqkyRkiJGfv6O6e4rPpeSmmA0wI315seYAtBtF11uUZFj5Dc19XODmU5G8D7ZQQgEv5w3N22fNBKScry3/P19CNoH9aVlXX6fSrTi+yHJH7Ywgb9aJXe9z02g9FFU1MBoKe4K0bXDSlwaec5hKC0zVDRUWat+wcvXhCLHvtu7gAAAABJRU5ErkJggg==","aspectRatio":3.75,"src":"/blog/static/a028acdce9731fb98fa789724cc1e8bf/3c17d/system-overviewv3.png","srcSet":"/blog/static/a028acdce9731fb98fa789724cc1e8bf/e0491/system-overviewv3.png 180w,\n/blog/static/a028acdce9731fb98fa789724cc1e8bf/f4094/system-overviewv3.png 360w,\n/blog/static/a028acdce9731fb98fa789724cc1e8bf/3c17d/system-overviewv3.png 720w,\n/blog/static/a028acdce9731fb98fa789724cc1e8bf/05d05/system-overviewv3.png 1080w,\n/blog/static/a028acdce9731fb98fa789724cc1e8bf/3bf79/system-overviewv3.png 1440w,\n/blog/static/a028acdce9731fb98fa789724cc1e8bf/17035/system-overviewv3.png 11697w","sizes":"(max-width: 720px) 100vw, 720px"}}}}}},"pageContext":{"slug":"/stylegan-drumsynth/","previous":{"fields":{"slug":"/breakbeat-manipulation/"},"frontmatter":{"title":"Breakbeat Manipulation with GANs","tags":["breakbeats","gans"]}},"next":{"fields":{"slug":"/in-the-loop/"},"frontmatter":{"title":"Improved Automatic Instrumentation Role Classification and Structural Analysis for Electronic Music Production","tags":["structure-analysis","classification","AIRC"]}}}},
    "staticQueryHashes": ["63159454"]}